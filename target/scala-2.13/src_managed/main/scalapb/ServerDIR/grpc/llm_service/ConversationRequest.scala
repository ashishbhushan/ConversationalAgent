// Generated by the Scala Plugin for the Protocol Buffer Compiler.
// Do not edit!
//
// Protofile syntax: PROTO3

package ServerDIR.grpc.llm_service

@SerialVersionUID(0L)
final case class ConversationRequest(
    prompt: _root_.scala.Predef.String = "",
    modelId: _root_.scala.Predef.String = "",
    maxTokenCount: _root_.scala.Int = 0,
    temperature: _root_.scala.Float = 0.0f,
    topP: _root_.scala.Float = 0.0f,
    unknownFields: _root_.scalapb.UnknownFieldSet = _root_.scalapb.UnknownFieldSet.empty
    ) extends scalapb.GeneratedMessage with scalapb.lenses.Updatable[ConversationRequest] {
    @transient
    private[this] var __serializedSizeMemoized: _root_.scala.Int = 0
    private[this] def __computeSerializedSize(): _root_.scala.Int = {
      var __size = 0
      
      {
        val __value = prompt
        if (!__value.isEmpty) {
          __size += _root_.com.google.protobuf.CodedOutputStream.computeStringSize(1, __value)
        }
      };
      
      {
        val __value = modelId
        if (!__value.isEmpty) {
          __size += _root_.com.google.protobuf.CodedOutputStream.computeStringSize(2, __value)
        }
      };
      
      {
        val __value = maxTokenCount
        if (__value != 0) {
          __size += _root_.com.google.protobuf.CodedOutputStream.computeInt32Size(3, __value)
        }
      };
      
      {
        val __value = temperature
        if (__value != 0.0f) {
          __size += _root_.com.google.protobuf.CodedOutputStream.computeFloatSize(4, __value)
        }
      };
      
      {
        val __value = topP
        if (__value != 0.0f) {
          __size += _root_.com.google.protobuf.CodedOutputStream.computeFloatSize(5, __value)
        }
      };
      __size += unknownFields.serializedSize
      __size
    }
    override def serializedSize: _root_.scala.Int = {
      var __size = __serializedSizeMemoized
      if (__size == 0) {
        __size = __computeSerializedSize() + 1
        __serializedSizeMemoized = __size
      }
      __size - 1
      
    }
    def writeTo(`_output__`: _root_.com.google.protobuf.CodedOutputStream): _root_.scala.Unit = {
      {
        val __v = prompt
        if (!__v.isEmpty) {
          _output__.writeString(1, __v)
        }
      };
      {
        val __v = modelId
        if (!__v.isEmpty) {
          _output__.writeString(2, __v)
        }
      };
      {
        val __v = maxTokenCount
        if (__v != 0) {
          _output__.writeInt32(3, __v)
        }
      };
      {
        val __v = temperature
        if (__v != 0.0f) {
          _output__.writeFloat(4, __v)
        }
      };
      {
        val __v = topP
        if (__v != 0.0f) {
          _output__.writeFloat(5, __v)
        }
      };
      unknownFields.writeTo(_output__)
    }
    def withPrompt(__v: _root_.scala.Predef.String): ConversationRequest = copy(prompt = __v)
    def withModelId(__v: _root_.scala.Predef.String): ConversationRequest = copy(modelId = __v)
    def withMaxTokenCount(__v: _root_.scala.Int): ConversationRequest = copy(maxTokenCount = __v)
    def withTemperature(__v: _root_.scala.Float): ConversationRequest = copy(temperature = __v)
    def withTopP(__v: _root_.scala.Float): ConversationRequest = copy(topP = __v)
    def withUnknownFields(__v: _root_.scalapb.UnknownFieldSet) = copy(unknownFields = __v)
    def discardUnknownFields = copy(unknownFields = _root_.scalapb.UnknownFieldSet.empty)
    def getFieldByNumber(__fieldNumber: _root_.scala.Int): _root_.scala.Any = {
      (__fieldNumber: @_root_.scala.unchecked) match {
        case 1 => {
          val __t = prompt
          if (__t != "") __t else null
        }
        case 2 => {
          val __t = modelId
          if (__t != "") __t else null
        }
        case 3 => {
          val __t = maxTokenCount
          if (__t != 0) __t else null
        }
        case 4 => {
          val __t = temperature
          if (__t != 0.0f) __t else null
        }
        case 5 => {
          val __t = topP
          if (__t != 0.0f) __t else null
        }
      }
    }
    def getField(__field: _root_.scalapb.descriptors.FieldDescriptor): _root_.scalapb.descriptors.PValue = {
      _root_.scala.Predef.require(__field.containingMessage eq companion.scalaDescriptor)
      (__field.number: @_root_.scala.unchecked) match {
        case 1 => _root_.scalapb.descriptors.PString(prompt)
        case 2 => _root_.scalapb.descriptors.PString(modelId)
        case 3 => _root_.scalapb.descriptors.PInt(maxTokenCount)
        case 4 => _root_.scalapb.descriptors.PFloat(temperature)
        case 5 => _root_.scalapb.descriptors.PFloat(topP)
      }
    }
    def toProtoString: _root_.scala.Predef.String = _root_.scalapb.TextFormat.printToUnicodeString(this)
    def companion: ServerDIR.grpc.llm_service.ConversationRequest.type = ServerDIR.grpc.llm_service.ConversationRequest
    // @@protoc_insertion_point(GeneratedMessage[ServerDIR.ConversationRequest])
}

object ConversationRequest extends scalapb.GeneratedMessageCompanion[ServerDIR.grpc.llm_service.ConversationRequest] {
  implicit def messageCompanion: scalapb.GeneratedMessageCompanion[ServerDIR.grpc.llm_service.ConversationRequest] = this
  def parseFrom(`_input__`: _root_.com.google.protobuf.CodedInputStream): ServerDIR.grpc.llm_service.ConversationRequest = {
    var __prompt: _root_.scala.Predef.String = ""
    var __modelId: _root_.scala.Predef.String = ""
    var __maxTokenCount: _root_.scala.Int = 0
    var __temperature: _root_.scala.Float = 0.0f
    var __topP: _root_.scala.Float = 0.0f
    var `_unknownFields__`: _root_.scalapb.UnknownFieldSet.Builder = null
    var _done__ = false
    while (!_done__) {
      val _tag__ = _input__.readTag()
      _tag__ match {
        case 0 => _done__ = true
        case 10 =>
          __prompt = _input__.readStringRequireUtf8()
        case 18 =>
          __modelId = _input__.readStringRequireUtf8()
        case 24 =>
          __maxTokenCount = _input__.readInt32()
        case 37 =>
          __temperature = _input__.readFloat()
        case 45 =>
          __topP = _input__.readFloat()
        case tag =>
          if (_unknownFields__ == null) {
            _unknownFields__ = new _root_.scalapb.UnknownFieldSet.Builder()
          }
          _unknownFields__.parseField(tag, _input__)
      }
    }
    ServerDIR.grpc.llm_service.ConversationRequest(
        prompt = __prompt,
        modelId = __modelId,
        maxTokenCount = __maxTokenCount,
        temperature = __temperature,
        topP = __topP,
        unknownFields = if (_unknownFields__ == null) _root_.scalapb.UnknownFieldSet.empty else _unknownFields__.result()
    )
  }
  implicit def messageReads: _root_.scalapb.descriptors.Reads[ServerDIR.grpc.llm_service.ConversationRequest] = _root_.scalapb.descriptors.Reads{
    case _root_.scalapb.descriptors.PMessage(__fieldsMap) =>
      _root_.scala.Predef.require(__fieldsMap.keys.forall(_.containingMessage eq scalaDescriptor), "FieldDescriptor does not match message type.")
      ServerDIR.grpc.llm_service.ConversationRequest(
        prompt = __fieldsMap.get(scalaDescriptor.findFieldByNumber(1).get).map(_.as[_root_.scala.Predef.String]).getOrElse(""),
        modelId = __fieldsMap.get(scalaDescriptor.findFieldByNumber(2).get).map(_.as[_root_.scala.Predef.String]).getOrElse(""),
        maxTokenCount = __fieldsMap.get(scalaDescriptor.findFieldByNumber(3).get).map(_.as[_root_.scala.Int]).getOrElse(0),
        temperature = __fieldsMap.get(scalaDescriptor.findFieldByNumber(4).get).map(_.as[_root_.scala.Float]).getOrElse(0.0f),
        topP = __fieldsMap.get(scalaDescriptor.findFieldByNumber(5).get).map(_.as[_root_.scala.Float]).getOrElse(0.0f)
      )
    case _ => throw new RuntimeException("Expected PMessage")
  }
  def javaDescriptor: _root_.com.google.protobuf.Descriptors.Descriptor = LlmServiceProto.javaDescriptor.getMessageTypes().get(0)
  def scalaDescriptor: _root_.scalapb.descriptors.Descriptor = LlmServiceProto.scalaDescriptor.messages(0)
  def messageCompanionForFieldNumber(__number: _root_.scala.Int): _root_.scalapb.GeneratedMessageCompanion[_] = throw new MatchError(__number)
  lazy val nestedMessagesCompanions: Seq[_root_.scalapb.GeneratedMessageCompanion[_ <: _root_.scalapb.GeneratedMessage]] = Seq.empty
  def enumCompanionForFieldNumber(__fieldNumber: _root_.scala.Int): _root_.scalapb.GeneratedEnumCompanion[_] = throw new MatchError(__fieldNumber)
  lazy val defaultInstance = ServerDIR.grpc.llm_service.ConversationRequest(
    prompt = "",
    modelId = "",
    maxTokenCount = 0,
    temperature = 0.0f,
    topP = 0.0f
  )
  implicit class ConversationRequestLens[UpperPB](_l: _root_.scalapb.lenses.Lens[UpperPB, ServerDIR.grpc.llm_service.ConversationRequest]) extends _root_.scalapb.lenses.ObjectLens[UpperPB, ServerDIR.grpc.llm_service.ConversationRequest](_l) {
    def prompt: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Predef.String] = field(_.prompt)((c_, f_) => c_.copy(prompt = f_))
    def modelId: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Predef.String] = field(_.modelId)((c_, f_) => c_.copy(modelId = f_))
    def maxTokenCount: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Int] = field(_.maxTokenCount)((c_, f_) => c_.copy(maxTokenCount = f_))
    def temperature: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Float] = field(_.temperature)((c_, f_) => c_.copy(temperature = f_))
    def topP: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Float] = field(_.topP)((c_, f_) => c_.copy(topP = f_))
  }
  final val PROMPT_FIELD_NUMBER = 1
  final val MODEL_ID_FIELD_NUMBER = 2
  final val MAX_TOKEN_COUNT_FIELD_NUMBER = 3
  final val TEMPERATURE_FIELD_NUMBER = 4
  final val TOP_P_FIELD_NUMBER = 5
  def of(
    prompt: _root_.scala.Predef.String,
    modelId: _root_.scala.Predef.String,
    maxTokenCount: _root_.scala.Int,
    temperature: _root_.scala.Float,
    topP: _root_.scala.Float
  ): _root_.ServerDIR.grpc.llm_service.ConversationRequest = _root_.ServerDIR.grpc.llm_service.ConversationRequest(
    prompt,
    modelId,
    maxTokenCount,
    temperature,
    topP
  )
  // @@protoc_insertion_point(GeneratedMessageCompanion[ServerDIR.ConversationRequest])
}
