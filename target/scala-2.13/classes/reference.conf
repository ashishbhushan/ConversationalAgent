ollama {
    # Default values - will be used if not overridden
    host = "http://localhost:11434"
    model = "tinyllama"
    temperature = 0.5
    num-predict = 200
    timeout = 300
    request-timeout-seconds = 300
}